{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309b6405",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸ–ï¸ MediaPipe Hands â€” ì†ê°€ë½ ì¹´ìš´íŠ¸ + ì œìŠ¤ì²˜ ë¼ë²¨ë§ (í™”ë©´ë§ì¶¤)\n",
    "\n",
    "**ì†ê°€ë½ í´ì§ ê°œìˆ˜**ë¥¼ ê³„ì‚°í•˜ê³ , ë‹¨ìˆœ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ **ì œìŠ¤ì²˜ ë¼ë²¨**ì„ ë¶™ì…ë‹ˆë‹¤.  \n",
    "ì¹´ë©”ë¼ ì¬ì‹œë„ ì´ˆê¸°í™”, ë ˆí„°ë°•ì‹±(Screen-Fit), FPS ì˜¤ë²„ë ˆì´, ë‹¨ì¶•í‚¤, ìŠ¤ëƒ…ìƒ· ì €ì¥ ë“± ê¸°ì¡´ UX ìœ ì§€.\n",
    "\n",
    "**ì œìŠ¤ì²˜ ê·œì¹™ ì˜ˆì‹œ (ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±)**\n",
    "- **Thumbs Up**: ì—„ì§€ë§Œ í´ì§\n",
    "- **Point (One)**: ê²€ì§€ë§Œ í´ì§\n",
    "- **Peace (Two / V)**: ê²€ì§€+ì¤‘ì§€ë§Œ í´ì§\n",
    "- **Three**: ê²€ì§€+ì¤‘ì§€+ì•½ì§€ í´ì§\n",
    "- **Rock (Rockâ€™nâ€™Roll)**: ê²€ì§€+ìƒˆë¼ í´ì§\n",
    "- **Five (Open Palm)**: 5ê°œ ëª¨ë‘ í´ì§\n",
    "- ê·¸ ì™¸: **Unknown**  \n",
    "> í•„ìš” ì‹œ ì–¸ì œë“  ê·œì¹™ì„ ì¶”ê°€/ìˆ˜ì •í•˜ì„¸ìš”!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a14b7",
   "metadata": {},
   "source": [
    "\n",
    "## 1) ì„¤ì¹˜ (í•„ìš” ì‹œë§Œ ì‹¤í–‰)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d1afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install --upgrade pip\n",
    "# !pip install mediapipe opencv-python screeninfo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25430666",
   "metadata": {},
   "source": [
    "\n",
    "## 2) ëª¨ë“ˆ ì„í¬íŠ¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230027d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe\n",
    "try:\n",
    "    import mediapipe as mp\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"mediapipeê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ìœ„ ì„¤ì¹˜ ì…€ì„ ì‹¤í–‰í•˜ì„¸ìš”.\") from e\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_styles   = mp.solutions.drawing_styles\n",
    "mp_hands    = mp.solutions.hands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64caa2a",
   "metadata": {},
   "source": [
    "\n",
    "## 3) í™”ë©´ í•´ìƒë„ íƒì§€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c94046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_screen_size():\n",
    "    try:\n",
    "        from screeninfo import get_monitors\n",
    "        m = get_monitors()[0]\n",
    "        return int(m.width), int(m.height)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        import tkinter as tk\n",
    "        root = tk.Tk()\n",
    "        root.withdraw()\n",
    "        w = root.winfo_screenwidth()\n",
    "        h = root.winfo_screenheight()\n",
    "        root.destroy()\n",
    "        return int(w), int(h)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 1280, 720\n",
    "\n",
    "SCREEN_W, SCREEN_H = _get_screen_size()\n",
    "print(f\"[INFO] Screen size detected: {SCREEN_W}x{SCREEN_H}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9a490",
   "metadata": {},
   "source": [
    "\n",
    "## 4) ì„¤ì •ê°’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c61b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "USE_CAMERA   = True\n",
    "CAP_INDEX    = 0\n",
    "VIDEO_SOURCE = \"./sample.mp4\"\n",
    "\n",
    "WINDOW_NAME = \"MediaPipe Hands â€” Gestures\"\n",
    "SAVE_DIR = \"./mp_gesture_snaps\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# ê²½ê³  ê¸°ì¤€: ì´ í´ì§„ ì†ê°€ë½ ìˆ˜\n",
    "COUNT_THRESHOLD = 8\n",
    "\n",
    "# MediaPipe Hands íŒŒë¼ë¯¸í„°\n",
    "HANDS_MAX_NUM = 2\n",
    "HANDS_DET_CONF = 0.5\n",
    "HANDS_TRK_CONF = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7285007",
   "metadata": {},
   "source": [
    "\n",
    "## 5) ì¹´ë©”ë¼ ì´ˆê¸°í™” (ì¬ì‹œë„)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a3bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_camera_with_retry(index=0):\n",
    "    methods = [\n",
    "        {\n",
    "            'name': 'V4L2_YUYV',\n",
    "            'backend': cv2.CAP_V4L2,\n",
    "            'settings': {\n",
    "                'fourcc': cv2.VideoWriter_fourcc('Y', 'U', 'Y', 'V'),\n",
    "                'width': 640,\n",
    "                'height': 480,\n",
    "                'fps': 30,\n",
    "                'buffersize': 1,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'V4L2_MJPEG',\n",
    "            'backend': cv2.CAP_V4L2,\n",
    "            'settings': {\n",
    "                'fourcc': cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'),\n",
    "                'width': 640,\n",
    "                'height': 480,\n",
    "                'fps': 30,\n",
    "                'buffersize': 1,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'DEFAULT',\n",
    "            'backend': None,\n",
    "            'settings': {\n",
    "                'width': 640,\n",
    "                'height': 480,\n",
    "                'fps': 30,\n",
    "                'buffersize': 1,\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for method in methods:\n",
    "        print(f\"[CAM] Trying {method['name']}...\")\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(index) if method['backend'] is None else cv2.VideoCapture(index, method['backend'])\n",
    "            if not cap.isOpened():\n",
    "                print(f\"[CAM] Open failed with {method['name']}\")\n",
    "                continue\n",
    "\n",
    "            s = method['settings']\n",
    "            if 'fourcc' in s:\n",
    "                cap.set(cv2.CAP_PROP_FOURCC, s['fourcc'])\n",
    "            cap.set(cv2.CAP_PROP_FRAME_WIDTH,  s['width'])\n",
    "            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, s['height'])\n",
    "            cap.set(cv2.CAP_PROP_FPS,          s['fps'])\n",
    "            cap.set(cv2.CAP_PROP_BUFFERSIZE,   s['buffersize'])\n",
    "\n",
    "            time.sleep(1.0)\n",
    "\n",
    "            ok_cnt = 0\n",
    "            for _ in range(5):\n",
    "                ret, f = cap.read()\n",
    "                if ret and f is not None:\n",
    "                    ok_cnt += 1\n",
    "                time.sleep(0.1)\n",
    "\n",
    "            if ok_cnt >= 3:\n",
    "                print(f\"[CAM] Ready with {method['name']}\")\n",
    "                return cap, method['name']\n",
    "            else:\n",
    "                print(f\"[CAM] Unstable with {method['name']}\")\n",
    "                cap.release()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[CAM] Error on {method['name']}: {e}\")\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8b58a",
   "metadata": {},
   "source": [
    "\n",
    "## 6) í™”ë©´ë§ì¶¤ & ì†ê°€ë½ ì¹´ìš´íŠ¸ & ì œìŠ¤ì²˜ ë¶„ë¥˜ ìœ í‹¸\n",
    "- ì—„ì§€: handedness ê¸°ì¤€ `TIP.x` vs `IP.x`\n",
    "- ë‚˜ë¨¸ì§€: `TIP.y < PIP.y`ë©´ í´ì§\n",
    "- `classify_gesture(opens)`ë¡œ ì œìŠ¤ì²˜ ë¬¸ìì—´ ë°˜í™˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def letterbox_fit_to_screen(frame, screen_w, screen_h, color=(0,0,0)):\n",
    "    h, w = frame.shape[:2]\n",
    "    scale = min(screen_w / w, screen_h / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    canvas = np.zeros((screen_h, screen_w, 3), dtype=np.uint8)\n",
    "    canvas[:] = color\n",
    "    x_off = (screen_w - new_w) // 2\n",
    "    y_off = (screen_h - new_h) // 2\n",
    "    canvas[y_off:y_off+new_h, x_off:x_off+new_w] = resized\n",
    "    return canvas, scale, x_off, y_off\n",
    "\n",
    "# MediaPipe Hands ì¸ë±ìŠ¤\n",
    "THUMB_TIP = 4\n",
    "THUMB_IP  = 3\n",
    "INDEX_TIP = 8\n",
    "INDEX_PIP = 6\n",
    "MIDDLE_TIP = 12\n",
    "MIDDLE_PIP = 10\n",
    "RING_TIP = 16\n",
    "RING_PIP = 14\n",
    "PINKY_TIP = 20\n",
    "PINKY_PIP = 18\n",
    "\n",
    "def count_fingers_one_hand(hand_landmarks, handed_label):\n",
    "    lm = hand_landmarks.landmark\n",
    "    # ì—„ì§€: ì¢Œ/ìš°ì— ë”°ë¼ x ë¹„êµ ë°©í–¥ ë°˜ëŒ€ë¡œ\n",
    "    if handed_label.lower().startswith(\"right\"):\n",
    "        thumb_open = lm[THUMB_TIP].x < lm[THUMB_IP].x\n",
    "    else:\n",
    "        thumb_open = lm[THUMB_TIP].x > lm[THUMB_IP].x\n",
    "\n",
    "    index_open  = lm[INDEX_TIP].y  < lm[INDEX_PIP].y\n",
    "    middle_open = lm[MIDDLE_TIP].y < lm[MIDDLE_PIP].y\n",
    "    ring_open   = lm[RING_TIP].y   < lm[RING_PIP].y\n",
    "    pinky_open  = lm[PINKY_TIP].y  < lm[PINKY_PIP].y\n",
    "\n",
    "    opens = [thumb_open, index_open, middle_open, ring_open, pinky_open]\n",
    "    return sum(int(v) for v in opens), opens\n",
    "\n",
    "def classify_gesture(opens):\n",
    "    # opens = [thumb, index, middle, ring, pinky] (bools)\n",
    "    t, i, m, r, p = opens\n",
    "    count = int(t) + int(i) + int(m) + int(r) + int(p)\n",
    "\n",
    "    if count == 5:\n",
    "        return \"Open Palm (Five)\"\n",
    "    if count == 0:\n",
    "        return \"Fist (Zero)\"\n",
    "    if count == 1:\n",
    "        if t and not any([i,m,r,p]):\n",
    "            return \"Thumbs Up\"\n",
    "        if i and not any([t,m,r,p]):\n",
    "            return \"Point (One)\"\n",
    "    if count == 2:\n",
    "        if i and m and not any([t,r,p]):\n",
    "            return \"Peace (Two)\"\n",
    "        if i and p and not any([t,m,r]):\n",
    "            return \"Rock\"\n",
    "    if count == 3:\n",
    "        if i and m and r and not any([t,p]):\n",
    "            return \"Three\"\n",
    "    # ê·¸ ì™¸\n",
    "    return f\"Unknown ({count})\"\n",
    "\n",
    "def put_label_near_wrist(bgr, hand_landmarks, handed_label, gesture, count):\n",
    "    h, w = bgr.shape[:2]\n",
    "    wrist = hand_landmarks.landmark[0]\n",
    "    px, py = int(wrist.x * w), int(wrist.y * h)\n",
    "    txt = f\"{handed_label}: {gesture} [{count}]\"\n",
    "    cv2.putText(bgr, txt, (px+10, py-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255), 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11a8fc",
   "metadata": {},
   "source": [
    "\n",
    "## 7) ì‹¤ì‹œê°„ ì¶”ë¡  ë£¨í”„ (ì œìŠ¤ì²˜ ë¼ë²¨ í¬í•¨)\n",
    "- ê° ì†ë§ˆë‹¤ ì œìŠ¤ì²˜ ë¼ë²¨ì„ wrist ê·¼ì²˜ì— í‘œê¸°\n",
    "- ì´ í´ì§„ ì†ê°€ë½ ìˆ˜ê°€ `COUNT_THRESHOLD` ì´ìƒì´ë©´ ì½˜ì†” ê²½ê³ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd4050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"[INFO] Starting MediaPipe Hands â€” Gestures...\")\n",
    "\n",
    "if USE_CAMERA:\n",
    "    cap, cam_method = setup_camera_with_retry(CAP_INDEX)\n",
    "    if cap is None:\n",
    "        raise SystemExit(\"[FATAL] ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨\")\n",
    "    src_desc = f\"camera:{CAP_INDEX} ({cam_method})\"\n",
    "else:\n",
    "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "    if not cap.isOpened():\n",
    "        raise SystemExit(f\"[FATAL] ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {VIDEO_SOURCE}\")\n",
    "    src_desc = f\"video:{VIDEO_SOURCE}\"\n",
    "\n",
    "print(f\"[INFO] Source: {src_desc}\")\n",
    "cv2.namedWindow(WINDOW_NAME, cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow(WINDOW_NAME, SCREEN_W, SCREEN_H)\n",
    "\n",
    "fullscreen = False\n",
    "fps = 0.0\n",
    "frame_count = 0\n",
    "last_time = time.time()\n",
    "\n",
    "hands_ctx = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=HANDS_MAX_NUM,\n",
    "    min_detection_confidence=HANDS_DET_CONF,\n",
    "    min_tracking_confidence=HANDS_TRK_CONF,\n",
    ")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"[WARN] Frame read failed\")\n",
    "            time.sleep(0.05)\n",
    "            continue\n",
    "\n",
    "        # ì…€í”¼ ìŠ¤íƒ€ì¼\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # MediaPipeëŠ” RGB ì…ë ¥ ê¶Œì¥\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands_ctx.process(rgb)\n",
    "\n",
    "        vis = frame.copy()\n",
    "        total_open = 0\n",
    "        left_count = 0\n",
    "        right_count = 0\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            # handedness ì •ë³´(ì¢Œ/ìš°) ë§¤ì¹­\n",
    "            handedness_list = []\n",
    "            if results.multi_handedness:\n",
    "                for hlabel in results.multi_handedness:\n",
    "                    handedness_list.append(hlabel.classification[0].label)\n",
    "            else:\n",
    "                handedness_list = [\"Unknown\"] * len(results.multi_hand_landmarks)\n",
    "\n",
    "            for hand_lm, handed_label in zip(results.multi_hand_landmarks, handedness_list):\n",
    "                # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    vis, hand_lm, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_styles.get_default_hand_connections_style(),\n",
    "                )\n",
    "                # ì†ê°€ë½ ê°œìˆ˜ + ì œìŠ¤ì²˜\n",
    "                cnt, opens = count_fingers_one_hand(hand_lm, handed_label)\n",
    "                gesture = classify_gesture(opens)\n",
    "                put_label_near_wrist(vis, hand_lm, handed_label, gesture, cnt)\n",
    "\n",
    "                total_open += cnt\n",
    "                if handed_label.lower().startswith(\"left\"):\n",
    "                    left_count = cnt\n",
    "                elif handed_label.lower().startswith(\"right\"):\n",
    "                    right_count = cnt\n",
    "\n",
    "        # í™”ë©´ ë§ì¶¤(ë ˆí„°ë°•ì‹±)\n",
    "        disp, scale, x_off, y_off = letterbox_fit_to_screen(vis, SCREEN_W, SCREEN_H, color=(0,0,0))\n",
    "\n",
    "        # FPS\n",
    "        frame_count += 1\n",
    "        if frame_count % 30 == 0:\n",
    "            now = time.time()\n",
    "            fps = 30.0 / (now - last_time)\n",
    "            last_time = now\n",
    "\n",
    "        # HUD\n",
    "        hud = f\"Left: {left_count} | Right: {right_count} | Total open: {total_open} | FPS: {fps:.1f}\"\n",
    "        cv2.putText(disp, hud, (10, SCREEN_H-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)\n",
    "\n",
    "        # ì½˜ì†” ì¶œë ¥ ë° ì„ê³„ì¹˜ ê²½ê³ \n",
    "        print(f\"[INFO] Open fingers â€” Left:{left_count} Right:{right_count} Total:{total_open}\")\n",
    "        if total_open >= COUNT_THRESHOLD:\n",
    "            print(f\"âš ï¸ Total finger open count >= {COUNT_THRESHOLD}!\")\n",
    "\n",
    "        cv2.imshow(WINDOW_NAME, disp)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == 27:\n",
    "            print(\"[INFO] Exit requested.\")\n",
    "            break\n",
    "        elif key == ord('f'):\n",
    "            fullscreen = not fullscreen\n",
    "            prop = cv2.WND_PROP_FULLSCREEN\n",
    "            cv2.setWindowProperty(WINDOW_NAME, prop, cv2.WINDOW_FULLSCREEN if fullscreen else cv2.WINDOW_NORMAL)\n",
    "            if not fullscreen:\n",
    "                cv2.resizeWindow(WINDOW_NAME, SCREEN_W, SCREEN_H)\n",
    "        elif key == ord('s'):\n",
    "            ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            path = os.path.join(SAVE_DIR, f\"mp_gesture_{ts}.jpg\")\n",
    "            cv2.imwrite(path, vis)\n",
    "            print(f\"[SAVE] Snapshot: {path}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"[INFO] Interrupted by user.\")\n",
    "\n",
    "finally:\n",
    "    if cap is not None:\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    hands_ctx.close()\n",
    "    print(\"[CLEANUP] Released resources.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce56913",
   "metadata": {},
   "source": [
    "\n",
    "## 8) ì°¸ê³  & í™•ì¥ ì•„ì´ë””ì–´\n",
    "- ê·œì¹™ì€ ê°„ë‹¨ íœ´ë¦¬ìŠ¤í‹±ì…ë‹ˆë‹¤. ì˜¤ì°¨ ê°ì†Œë¥¼ ì›í•˜ë©´ ê° ê´€ì ˆ ë²¡í„°ì˜ ê°ë„ë¥¼ ì´ìš©í•´ **ì •ê·œí™”ëœ í¬ì¦ˆ ë¶„ë¥˜ê¸°**ë¡œ í™•ì¥í•˜ì„¸ìš”.\n",
    "- íŠ¹ì • ì œìŠ¤ì²˜ì—ì„œë§Œ **ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°**(ì˜ˆ: \"Thumbs Upì´ë©´ ì´¬ì˜\", \"Peaceì´ë©´ ì €ì¥\")ë„ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- ë©€í‹°í”„ë ˆì„ **ë””ë°”ìš´ì‹±/ì•ˆì •í™”**ê°€ í•„ìš”í•˜ë©´ ìµœê·¼ Ní”„ë ˆì„ì˜ ì œìŠ¤ì²˜ë¥¼ `deque`ë¡œ ëª¨ì•„ **ìµœë¹ˆê°’**ì„ í‘œì‹œí•´ë³´ì„¸ìš”.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
