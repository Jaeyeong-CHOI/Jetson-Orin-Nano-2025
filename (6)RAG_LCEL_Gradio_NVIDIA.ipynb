{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec5574e",
   "metadata": {},
   "source": [
    "# âœ… LCEL + PDF RAG + Gradio ì±—ë´‡ (NVIDIA API ì‚¬ìš©)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **NVIDIA API(OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸)**ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì„ í˜¸ì¶œí•˜ê³ , LangChainì˜ **LCEL**ë¡œ RAG íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•œ ë’¤, **Gradio**ë¡œ ê°„ë‹¨í•œ ì±—ë´‡ UIë¥¼ ë§Œë“œëŠ” ì˜ˆì œì…ë‹ˆë‹¤.\n",
    "\n",
    "êµ¬ì„±:\n",
    "1) **LCEL ê¸°ë³¸ ì˜ˆì œ** (RAGì— í•„ìš”í•œ ìˆ˜ì¤€ë§Œ)  \n",
    "2) **PDF ë¡œë”© â†’ ì²­í¬ ë¶„í•  â†’ ì„ë² ë”© â†’ ë²¡í„°ìŠ¤í† ì–´(FAISS)**  \n",
    "3) **LLM ë‹¨ë… Gradio ì±—ë´‡** (NVIDIA API, Mixtral 8x7B)  \n",
    "4) **RAG ê¸°ë°˜ Gradio ì±—ë´‡** (PDF ì§€ì‹ ê¸°ë°˜)  \n",
    "\n",
    "> ëª¨ë“  ì„¤ëª…/í”„ë¡¬í”„íŠ¸ëŠ” í•œêµ­ì–´ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b2a66a",
   "metadata": {},
   "source": [
    "## 0) í™˜ê²½ ì„¤ì • ë° ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f7297f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ê±´ë„ˆë›°ì–´ë„ ë©ë‹ˆë‹¤)\n",
    "# LangChain ìµœì‹  ë²„ì „ì—ì„œëŠ” ì»¤ë®¤ë‹ˆí‹° ì»´í¬ë„ŒíŠ¸ê°€ ë¶„ë¦¬ë˜ì–´ ìˆì–´ ì•„ë˜ íŒ¨í‚¤ì§€ë¥¼ í•¨ê»˜ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# %pip install -U langchain langchain-openai langchain-community langchain-huggingface                     sentence-transformers faiss-cpu PyPDF2 gradio requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9103f41",
   "metadata": {},
   "source": [
    "## 1) NVIDIA API í‚¤ ì„¤ì • ë° ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ë°ëª¨\n",
    "\n",
    "- NVIDIA APIëŠ” OpenAI í˜¸í™˜ **Chat Completions** ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.  \n",
    "- ì•„ë˜ ì½”ë“œëŠ” **ìŠ¤íŠ¸ë¦¬ë°**ìœ¼ë¡œ í† í°ì„ ë°›ì•„ ì¶œë ¥í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.  \n",
    "- ëª¨ë¸: `mistralai/mixtral-8x7b-instruct-v0.1`\n",
    "- API í‚¤ëŠ” ë‹¤ìŒ ë§í¬ì—ì„œ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. [https://build.nvidia.com/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c149d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â–¶ ëª¨ë¸ ì‘ë‹µ(ìŠ¤íŠ¸ë¦¬ë°): ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì–´ë¡œ ì¸ì‚¬í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. (Hello! Thank you for greeting me in Korean.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, json, requests\n",
    "from getpass import getpass\n",
    "\n",
    "#os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n",
    "\n",
    "# ğŸ”‘ API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì— ì €ì¥). í‚¤ê°€ ì—†ìœ¼ë©´ ì…ë ¥ì°½ì´ ëœ¹ë‹ˆë‹¤.\n",
    "if not os.environ.get(\"NVIDIA_API_KEY\", \"\").startswith(\"nvapi-\"):\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass(\"NVIDIA_API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš” (nvapi-...): \")\n",
    "\n",
    "invoke_url = \"https://integrate.api.nvidia.com/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"accept\": \"text/event-stream\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {os.environ['NVIDIA_API_KEY']}\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
    "    \"messages\": [{\"role\":\"user\",\"content\":\"ì•ˆë…•? í•œêµ­ì–´ë¡œ ì¸ì‚¬í•´ì¤˜\"}],\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 1,\n",
    "    \"max_tokens\": 256,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "def get_stream_token(entry: bytes):\n",
    "    \"\"\"ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì—ì„œ í† í° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\"\"\"\n",
    "    if not entry: return \"\"\n",
    "    entry = entry.decode(\"utf-8\")\n",
    "    if entry.startswith(\"data: \"):\n",
    "        try:\n",
    "            entry = json.loads(entry[6:])\n",
    "        except ValueError:\n",
    "            return \"\"\n",
    "    return entry.get(\"choices\", [{}])[0].get(\"delta\", {}).get(\"content\") or \"\"\n",
    "\n",
    "# ğŸš€ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ\n",
    "response = requests.post(invoke_url, headers=headers, json=payload, stream=True)\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception as e:\n",
    "    print(\"ì—ëŸ¬ ì‘ë‹µ:\", response.text)\n",
    "    raise e\n",
    "\n",
    "print(\"â–¶ ëª¨ë¸ ì‘ë‹µ(ìŠ¤íŠ¸ë¦¬ë°):\", end=\" \")\n",
    "for line in response.iter_lines():\n",
    "    print(get_stream_token(line), end=\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbf5a7",
   "metadata": {},
   "source": [
    "## 2) LCEL ê¸°ë³¸ ì˜ˆì œ (RAGì— í•„ìš”í•œ ìš”ì†Œ ìœ„ì£¼)\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LCELì˜ í•µì‹¬ì¸ `RunnableLambda`, `RunnableParallel`, `RunnablePassthrough` ì •ë„ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.  \n",
    "- **ëª©í‘œ**: ì…ë ¥ ì§ˆì˜ë¥¼ ë°›ì•„ ì „ì²˜ë¦¬ â†’ (ë³‘ë ¬ë¡œ) ì›ë³¸ ë³´ì¡´ ë° ì¶”ê°€ ì²˜ë¦¬ â†’ í›„ì²˜ë¦¬ êµ¬ì¡° ìµíˆê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dbb63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'RAGë€ ë¬´ì—‡ì¸ê°€', 'normalized': 'RAGë€ ë¬´ì—‡ì¸ê°€?', 'hint': 'ìš”ì•½íŒíŠ¸:RAGë€ ë¬´ì—‡ì¸ê°€...'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "def normalize_question(q: str) -> str:\n",
    "    # ê°„ë‹¨ ì „ì²˜ë¦¬: ì¢Œìš° ê³µë°± ì œê±° + ë§ˆì¹¨í‘œ ë³´ì •\n",
    "    q = (q or \"\").strip()\n",
    "    if q and q[-1] not in \".?!\":\n",
    "        q += \"?\"  # ì§ˆë¬¸ í˜•íƒœë¡œ ì •ê·œí™”\n",
    "    return q\n",
    "\n",
    "def summarize_hint(q: str) -> str:\n",
    "    # ë§¤ìš° ë‹¨ìˆœí•œ ìš”ì•½ íŒíŠ¸ (ì‹¤ì „ì—ì„œëŠ” LLM/ê·œì¹™ê¸°ë°˜ í™œìš©)\n",
    "    kw = q[:20]\n",
    "    return f\"ìš”ì•½íŒíŠ¸:{kw}...\"\n",
    "\n",
    "node_normalize = RunnableLambda(normalize_question)\n",
    "\n",
    "parallel = RunnableParallel({\n",
    "    \"original\": RunnablePassthrough(),\n",
    "    \"normalized\": node_normalize,\n",
    "    \"hint\": RunnableLambda(summarize_hint),\n",
    "})\n",
    "\n",
    "print(parallel.invoke(\"RAGë€ ë¬´ì—‡ì¸ê°€\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bee4b",
   "metadata": {},
   "source": [
    "## 3) PDF ë¡œë”© â†’ ë¶„í•  â†’ ì„ë² ë”© â†’ FAISS ë²¡í„°ìŠ¤í† ì–´\n",
    "\n",
    "- **DocumentLoader**: `PyPDFLoader` (LangChain Community)  \n",
    "- **í…ìŠ¤íŠ¸ ë¶„í• **: `RecursiveCharacterTextSplitter`  \n",
    "- **ì„ë² ë”©**: `sentence-transformers/all-MiniLM-L6-v2` (ë¡œì»¬)  \n",
    "- **ë²¡í„°ìŠ¤í† ì–´**: `FAISS`\n",
    "\n",
    "> `example.pdf` íŒŒì¼ì´ í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬ì— ì—†ë‹¤ë©´, ë°ëª¨ìš© ê°„ë‹¨ PDFë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "025d3f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example.pdf íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ë°ëª¨ìš© PDF ìë™ ìƒì„± (ì—†ì„ ë•Œë§Œ)\n",
    "pdf_path = \"example.pdf\"\n",
    "if not os.path.exists(pdf_path):\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.pagesizes import A4\n",
    "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "    text = c.beginText(40, 800)\n",
    "    text.textLines(\"\"\"\n",
    "ì´ ë¬¸ì„œëŠ” RAG ë°ëª¨ë¥¼ ìœ„í•´ ìë™ ìƒì„±ëœ PDFì…ë‹ˆë‹¤.\n",
    "RAG(Retrieval-Augmented Generation)ëŠ” ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•˜ì—¬,\n",
    "ì§ˆì˜ì™€ ê´€ë ¨ëœ ë¬¸ì„œ ì¡°ê°ì„ ë¨¼ì € ê²€ìƒ‰í•˜ê³ , í•´ë‹¹ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì—¬ê¸°ì— ì„ì˜ì˜ ì˜ˆì‹œ ë‚´ìš©ì„ ë” ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "- LCELì€ LangChainì—ì„œ ì²´ì¸ì„ êµ¬ì„±í•˜ê¸° ìœ„í•œ í‘œí˜„ ì–¸ì–´ì…ë‹ˆë‹¤.\n",
    "- RunnableLambda, RunnableParallel, RunnablePassthrough ë“±ì„ ì´ìš©í•´ íŒŒì´í”„ë¼ì¸ì„ ìœ ì—°í•˜ê²Œ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- ì´ ë¬¸ì„œì˜ ëª©ì ì€ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•ê³¼ RAG ì±—ë´‡ì˜ ë™ì‘ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\"\"\")\n",
    "    c.drawText(text)\n",
    "    c.showPage()\n",
    "    c.save()\n",
    "    print(\"ë°ëª¨ìš© example.pdfë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"example.pdf íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31cc0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜ì´ì§€ ìˆ˜: 6, ì²­í¬ ìˆ˜: 11\n",
      "ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\n",
      " RAGê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œì–¸ì–´ëª¨ë¸(LLM)ì˜ í•œê³„: íŒŒë¼ë¯¸í„° ì•ˆì— ë“  ì§€ì‹ì€ ìµœì‹ ì„±ì´ ë–¨ì–´ì§€ê³ , ì¶œì²˜ë¥¼ ì œì‹œí•˜ê¸° ì–´ë µê³ , ê¸¸ê²Œ ê¸°ì–µí•˜ì§€ë„ ëª»í•´ìš”.RAGì˜ ì•„ì´ë””ì–´: â€œë‹µì„ ë§Œë“¤ê¸° ì „ì— ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ ì»¨í…ìŠ¤íŠ¸ë¡œ ë„£ì–´ì¤€ë‹¤.â€â†’ ìµœì‹ ì„±, ì¶œì²˜ ì œì‹œ, ë„ë©”ì¸ íŠ¹í™” ì •í™•ë„ê°€ í¬ê²Œ ì¢‹ì•„ì§€ê³ , íŒŒë¼ë¯¸í„° ì¬í•™ìŠµ ì—†ì´ ì§€ì‹ë§Œ êµì²´Â·ì¦ë¶„ ì¶”ê°€ ê°€ëŠ¥.í° ê·¸\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"example.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=120,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"í˜ì´ì§€ ìˆ˜: {len(documents)}, ì²­í¬ ìˆ˜: {len(chunks)}\")\n",
    "print(\"ì²« ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\\n\", chunks[0].page_content[:200].replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66904c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1: ë©”ëª¨ë¦¬ RAG(ëŒ€í™” ì¥ê¸° ì»¨í…ìŠ¤íŠ¸)ì„¸ì…˜ ë©”ëª¨ë¦¬(ìš”ì•½) + ê°œì¸ ë…¸íŠ¸(ë³´ì•ˆ ì˜ì—­) + ë¬¸ì„œ RAG ê²°í•©10. ì‹¤íŒ¨ ëª¨ë“œ & ë””ë²„ê¹… ì²´í¬ë¦¬ìŠ¤íŠ¸ì¦ìƒ â†’ ì›ì¸ â†’ ì²˜ë°© ë¹ ë¥´ê²Œ ë§¤ì¹­í•˜ê¸°ê´€ë ¨ ë¬¸ì„œ ëª» ì°¾ìŒ â†’ ë¶„í•  ê³¼ë„/ë©”íƒ€ë° ...\n",
      "Top 2: RAGê°€ í•´ê²°í•˜ëŠ” ë¬¸ì œì–¸ì–´ëª¨ë¸(LLM)ì˜ í•œê³„: íŒŒë¼ë¯¸í„° ì•ˆì— ë“  ì§€ì‹ì€ ìµœì‹ ì„±ì´ ë–¨ì–´ì§€ê³ , ì¶œì²˜ë¥¼ ì œì‹œí•˜ê¸° ì–´ë µê³ , ê¸¸ê²Œ ê¸°ì–µí•˜ì§€ë„ ëª»í•´ìš”.RAGì˜ ì•„ì´ë””ì–´: â€œë‹µì„ ë§Œë“¤ê¸° ì „ì— ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(chunks, emb)\n",
    "\n",
    "# ê°„ë‹¨ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "docs = vectorstore.similarity_search(\"RAGì˜ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\", k=2)\n",
    "for i, d in enumerate(docs, 1):\n",
    "    print(f\"Top {i}:\", d.page_content[:120].replace(\"\\n\",\" \"),\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344a9acd",
   "metadata": {},
   "source": [
    "## 4) NVIDIA APIë¥¼ LangChain LLMìœ¼ë¡œ ì‚¬ìš©í•˜ê¸°\n",
    "\n",
    "`langchain-openai`ì˜ `ChatOpenAI`ë¥¼ ì‚¬ìš©í•˜ë˜, **base_url**ì„ NVIDIAë¡œ ì„¤ì •í•˜ë©´ OpenAI í˜¸í™˜ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc5b76ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ê·€í•˜ì˜ ì¼ì„ ë„ì™€ë“œë¦¬ê¸° ìœ„í•´ ìµœì„ ì„ ë‹¤í•˜ê² ìŠµë‹ˆë‹¤. (Hello, I will do my best to assist you.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ NVIDIA_API_KEYê°€ ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "assert os.environ.get(\"NVIDIA_API_KEY\",\"\").startswith(\"nvapi-\"), \"NVIDIA_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.3,\n",
    "    model=\"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
    "    api_key=os.environ[\"NVIDIA_API_KEY\"],\n",
    "    base_url=\"https://integrate.api.nvidia.com/v1\",\n",
    ")\n",
    "\n",
    "# ê°„ë‹¨ í˜¸ì¶œ\n",
    "resp = llm.invoke(\"í•œ ì¤„ í•œêµ­ì–´ ì¸ì‚¬ë§ì„ ì •ì¤‘í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.\")\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e40ca",
   "metadata": {},
   "source": [
    "## 5) LCELë¡œ RAG ì²´ì¸ êµ¬ì„± (Retriever â†’ Prompt í¬ë§· â†’ LLM)\n",
    "\n",
    "- `vectorstore.as_retriever(k=3)` ë¡œ ê²€ìƒ‰ ë…¸ë“œ êµ¬ì„±  \n",
    "- `RunnableParallel`ë¡œ ì§ˆë¬¸/ì»¨í…ìŠ¤íŠ¸ ë³‘ë ¬ ì²˜ë¦¬  \n",
    "- ì‚¬ìš©ì ì •ì˜ í¬ë§·í„°(`RunnableLambda`)ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±  \n",
    "- `ChatOpenAI` LLMì— ì „ë‹¬ â†’ ë‹µë³€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2837a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë¬¸ì„œì˜ ì£¼ì œëŠ” \"Retrieval-Augmented Generation (RAG)\"ì´ë‹¤. RAGëŠ” ì–¸ì–´ëª¨ë¸(LLM)ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì œì•ˆëœ ê¸°ìˆ ë¡œ, íŒŒë¼ë¯¸í„° ì•ˆì— ë“  ì§€ì‹ë³´ë‹¤ëŠ” ì™¸ë¶€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©í•˜ì—¬ ì •í™•ë„, ìµœì‹ ì„±, ì¶œì²˜ ì œì‹œ ì¸¡ë©´ì—ì„œ í° ì´ì ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
      "\n",
      "RAGì˜ í•µì‹¬ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ì§€ì‹ ìˆ˜ì§‘ ë° ì •ì œ: PDF, DOCX, ì›¹ ë“±ì—ì„œ ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•˜ê³ , ì „ì²˜ë¦¬ ê³¼ì •ì„ ê±°ì¹©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ë¬¸ì„œëŠ” í´ë¦°, ë¶„í• , ë©”íƒ€ë°ì´í„° ì²˜ë¦¬ê°€ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n",
      "2. ì¸ë±ì‹±: ë¬¸ì„œë¥¼ ë²¡í„°í™”í•˜ì—¬ ë²¡í„° DB ë˜ëŠ” ìƒ‰ì¸ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
      "3. ì§ˆì˜ ì²˜ë¦¬: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì„ë² ë”©í™”í•˜ê³ , ê²€ìƒ‰ê³¼ ì¬ìˆœìœ„í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±: ì¤‘ìš”í•œ ì¡°ê°ì„ ì„ íƒí•˜ì—¬ ê¸¸ì´ ì œí•œ ì•ˆì—ì„œ ì••ì¶•í•©ë‹ˆë‹¤.\n",
      "5. ë‹µë³€ ìƒì„±: LLM í”„ë¡¬í”„íŠ¸ì— ì»¨í…ìŠ¤íŠ¸ì™€ ì§€ì‹œë¬¸ì„ ë„£ì–´ ë‹µë³€ì„ ìƒì„±í•˜ë©°, ì¸ìš©ê³¼ ì¶œì²˜ë¥¼ í¬í•¨ì‹œí‚µë‹ˆë‹¤.\n",
      "6. í‰ê°€ ë° ë¡œê¹…: ì •í™•ì„±ê³¼ ì¶©ì‹¤ì„±, ë¹„ìš©, ì§€ì—° ì‹œê°„, ê´€ì¸¡ ë° ëª¨ë‹ˆí„°ë§, ìºì‹± ë° ì—…ë°ì´íŠ¸ ë“±ì„ í‰ê°€í•©ë‹ˆë‹¤.\n",
      "\n",
      "RAGëŠ” ë‹¤ì–‘í•œ í˜•íƒœë¡œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, ë©€í‹°ëª¨ë‹¬, ê³ ê¸‰ ê²€ìƒ‰, ê·¸ë˜í”„ ê¸°ë°˜ ì—°ê²° í˜•íƒœ ì§ˆì˜, ì—ì´ì „í‹± ê¸°ëŠ¥ ë“±ì„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnableLambda, RunnablePassthrough\n",
    "from langchain.schema import Document\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "def format_prompt(inputs: dict) -> str:\n",
    "    docs = inputs[\"context\"]\n",
    "    q = inputs[\"question\"]\n",
    "    ctx_text = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    prompt = (\n",
    "        \"ë‹¤ìŒ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ ë‹µí•˜ì‹­ì‹œì˜¤.\\n\"\n",
    "        \"ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ëŠ” ë‚´ìš©ì€ ì¶”ë¡ í•˜ì§€ ë§ê³  'ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ì„¸ìš”.\\n\"\n",
    "        \"=== ì»¨í…ìŠ¤íŠ¸ ì‹œì‘ ===\\n\"\n",
    "        f\"{ctx_text}\\n\"\n",
    "        \"=== ì»¨í…ìŠ¤íŠ¸ ë ===\\n\"\n",
    "        f\"ì§ˆë¬¸: {q}\\n\"\n",
    "        \"ë‹µë³€:\"\n",
    "    )\n",
    "    return prompt\n",
    "\n",
    "rag_node = RunnableParallel({\n",
    "    \"context\": retriever,\n",
    "    \"question\": RunnablePassthrough(),\n",
    "}) | RunnableLambda(format_prompt) | llm\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸\n",
    "print(rag_node.invoke(\"ì´ ë¬¸ì„œì˜ ì£¼ì œì™€ RAGì˜ í•µì‹¬ ê³¼ì •ì„ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959bd842",
   "metadata": {},
   "source": [
    "## 6) Gradio: LLM ë‹¨ë… ì±—ë´‡\n",
    "\n",
    "ê°„ë‹¨í•œ ì…ë ¥/ì¶œë ¥ ì±—ë´‡ UI. (RAG ë¯¸ì ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78108af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def chat_plain(user_input: str) -> str:\n",
    "    if not user_input or not user_input.strip():\n",
    "        return \"ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "    out = llm.invoke(\n",
    "        f\"ì•„ë˜ ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ì •ì¤‘í•œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\\nì‚¬ìš©ì: {user_input}\\nì‘ë‹µ:\"\n",
    "    )\n",
    "    return out.content\n",
    "\n",
    "demo_plain = gr.Interface(\n",
    "    fn=chat_plain,\n",
    "    inputs=gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”\"),\n",
    "    outputs=gr.Textbox(label=\"ëª¨ë¸ ì‘ë‹µ\"),\n",
    "    title=\"LLM ë‹¨ë… ì±—ë´‡ (NVIDIA Mixtral)\",\n",
    "    description=\"ê°„ë‹¨í•œ LLM ê¸°ë°˜ ì±—ë´‡ ë°ëª¨ì…ë‹ˆë‹¤.\"\n",
    ")\n",
    "# ì£¼í”¼í„°ì—ì„œ ì‹¤í–‰ ì‹œ ë³„ë„ì˜ ì™¸ë¶€ ë§í¬ê°€ í‘œì‹œë©ë‹ˆë‹¤.\n",
    "#demo_plain.launch()  # í•„ìš” ì‹œ ìˆ˜ë™ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea3272",
   "metadata": {},
   "source": [
    "## 7) Gradio: PDF ê¸°ë°˜ RAG ì±—ë´‡\n",
    "\n",
    "- ì‚¬ìš©ìì˜ ì§ˆë¬¸ â†’ ë²¡í„°ìŠ¤í† ì–´ ê²€ìƒ‰ â†’ í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ LLM í˜¸ì¶œ â†’ ë‹µë³€  \n",
    "- ê°„ë‹¨í•œ 1í„´ QA í˜•íƒœ (ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¯¸ë³´ì¡´)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0729aae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_rag(user_input: str) -> str:\n",
    "    if not user_input or not user_input.strip():\n",
    "        return \"ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.\"\n",
    "    try:\n",
    "        res = rag_node.invoke(user_input)\n",
    "        # ChatOpenAIëŠ” AIMessageë¥¼ ë°˜í™˜ â†’ .content\n",
    "        return getattr(res, \"content\", str(res))\n",
    "    except Exception as e:\n",
    "        return f\"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
    "\n",
    "demo_rag = gr.Interface(\n",
    "    fn=chat_rag,\n",
    "    inputs=gr.Textbox(label=\"ì§ˆë¬¸ ì…ë ¥\", placeholder=\"PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”\"),\n",
    "    outputs=gr.Textbox(label=\"RAG ì‘ë‹µ\"),\n",
    "    title=\"PDF ê¸°ë°˜ RAG ì±—ë´‡\",\n",
    "    description=\"example.pdf ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.\"\n",
    ")\n",
    "#demo_rag.launch()  # í•„ìš” ì‹œ ìˆ˜ë™ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a855319",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### âœ… íŒ / ë‹¤ìŒ ë‹¨ê³„\n",
    "- **PDF êµì²´**: `example.pdf` ëŒ€ì‹  ì‹¤ì œ PDF íŒŒì¼ì„ ê°™ì€ í´ë”ì— ë‘ê³  íŒŒì¼ëª…ì„ ë°”ê¾¸ì„¸ìš”.\n",
    "- **ìŠ¤íŠ¸ë¦¬ë° UI**: Gradioì—ì„œ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•˜ë ¤ë©´ `yield`ë¥¼ ì‚¬ìš©í•œ ì œë„ˆë ˆì´í„° í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì„¸ìš”.\n",
    "- **ëŒ€í™” íˆìŠ¤í† ë¦¬**: ê°„ë‹¨íˆëŠ” textboxì— ëˆ„ì í•´ ë„˜ê¸°ê±°ë‚˜, LangChainì˜ `MessagesPlaceholder`ë¥¼ ì‚¬ìš©í•´ í™•ì¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "- **ì„ë² ë”© ëª¨ë¸ êµì²´**: í•œêµ­ì–´ ì„±ëŠ¥ì„ ë†’ì´ë ¤ë©´ í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ë¡œ êµì²´í•˜ì„¸ìš”. (ì˜ˆ: `jhgan/ko-sroberta-multitask` ë“±)\n",
    "- **ë³´ì•ˆ**: ë…¸íŠ¸ë¶ ê³µìœ  ì‹œ API í‚¤ê°€ ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.\n",
    "\n",
    "í•„ìš”í•˜ë©´ `demo_plain.launch()` ë˜ëŠ” `demo_rag.launch()` ì…€ì„ ì‹¤í–‰í•˜ì—¬ UIë¥¼ ë„ìš°ì„¸ìš”."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
